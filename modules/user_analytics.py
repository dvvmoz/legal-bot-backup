"""
–ú–æ–¥—É–ª—å –¥–ª—è —Å–±–æ—Ä–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è ML-—Ñ–∏–ª—å—Ç—Ä–∞.
"""
import sqlite3
import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import pandas as pd

logger = logging.getLogger(__name__)

class UserAnalytics:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–±–æ—Ä–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö."""
    
    def __init__(self, db_path: str = "db/user_analytics.db"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏—Å—Ç–µ–º—É –∞–Ω–∞–ª–∏—Ç–∏–∫–∏.
        
        Args:
            db_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö SQLite
        """
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_database()
        logger.info(f"‚úÖ –°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {db_path}")
    
    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS user_questions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    question_text TEXT NOT NULL,
                    question_length INTEGER,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    ml_prediction BOOLEAN,
                    ml_confidence REAL,
                    ml_explanation TEXT,
                    was_accepted BOOLEAN,
                    search_result_quality TEXT,
                    search_distance REAL,
                    docs_found INTEGER,
                    source_type TEXT,  -- 'knowledge_base', 'dynamic_search', 'error'
                    response_length INTEGER,
                    processing_time_ms INTEGER,
                    keywords TEXT,  -- JSON –º–∞—Å—Å–∏–≤ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                    question_category TEXT,  -- –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
                    session_id TEXT  -- –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ—Å—Å–∏–∏
                )
            """)
            
            # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ (–≤–∞–∂–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS rejected_questions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    question_text TEXT NOT NULL,
                    question_length INTEGER,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    ml_confidence REAL,
                    ml_explanation TEXT,
                    user_feedback TEXT,  -- –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∂–∞–ª—É–µ—Ç—Å—è –Ω–∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
                    manual_review BOOLEAN DEFAULT FALSE,
                    should_be_legal BOOLEAN  -- —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                )
            """)
            
            # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS ml_performance (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    date DATE DEFAULT CURRENT_DATE,
                    total_questions INTEGER,
                    accepted_questions INTEGER,
                    rejected_questions INTEGER,
                    avg_confidence REAL,
                    low_confidence_count INTEGER,  -- < 0.7
                    high_confidence_count INTEGER,  -- > 0.9
                    false_positives INTEGER,  -- –æ—Ü–µ–Ω–æ—á–Ω–æ
                    false_negatives INTEGER,  -- –æ—Ü–µ–Ω–æ—á–Ω–æ
                    dynamic_search_triggered INTEGER,
                    knowledge_base_hits INTEGER
                )
            """)
            
            # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_questions_user_id ON user_questions(user_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_questions_timestamp ON user_questions(timestamp)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_questions_ml_prediction ON user_questions(ml_prediction)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_rejected_questions_timestamp ON rejected_questions(timestamp)")
            
            conn.commit()
            logger.info("üìä –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def log_question(self, user_id: int, question_text: str, ml_result: Tuple[bool, float, str], 
                    search_results: Dict[str, Any] = None, response_info: Dict[str, Any] = None,
                    session_id: str = None) -> int:
        """
        –õ–æ–≥–∏—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏.
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            question_text: –¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞
            ml_result: –†–µ–∑—É–ª—å—Ç–∞—Ç ML-—Ñ–∏–ª—å—Ç—Ä–∞ (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ)
            search_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
            response_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—Ç–≤–µ—Ç–µ
            session_id: ID —Å–µ—Å—Å–∏–∏
            
        Returns:
            ID –∑–∞–ø–∏—Å–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        """
        try:
            is_legal, confidence, explanation = ml_result
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            keywords = self._extract_keywords(question_text)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤–æ–ø—Ä–æ—Å–∞
            category = self._categorize_question(question_text, keywords)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
            question_data = {
                'user_id': user_id,
                'question_text': question_text,
                'question_length': len(question_text),
                'ml_prediction': is_legal,
                'ml_confidence': confidence,
                'ml_explanation': explanation,
                'was_accepted': is_legal,
                'keywords': json.dumps(keywords, ensure_ascii=False),
                'question_category': category,
                'session_id': session_id or f"session_{user_id}_{datetime.now().strftime('%Y%m%d_%H')}"
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∏—Å–∫–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
            if search_results:
                question_data.update({
                    'search_result_quality': search_results.get('quality', 'unknown'),
                    'search_distance': search_results.get('best_distance'),
                    'docs_found': search_results.get('docs_count', 0),
                    'source_type': search_results.get('source_type', 'unknown')
                })
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—Ç–≤–µ—Ç–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
            if response_info:
                question_data.update({
                    'response_length': response_info.get('response_length', 0),
                    'processing_time_ms': response_info.get('processing_time_ms', 0)
                })
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                if is_legal:
                    # –í–æ–ø—Ä–æ—Å –ø—Ä–∏–Ω—è—Ç - –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –æ—Å–Ω–æ–≤–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
                    columns = ', '.join(question_data.keys())
                    placeholders = ', '.join(['?' for _ in question_data])
                    query = f"INSERT INTO user_questions ({columns}) VALUES ({placeholders})"
                    cursor.execute(query, list(question_data.values()))
                else:
                    # –í–æ–ø—Ä–æ—Å –æ—Ç–∫–ª–æ–Ω–µ–Ω - –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ç–∞–±–ª–∏—Ü—É –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã—Ö
                    rejected_data = {
                        'user_id': user_id,
                        'question_text': question_text,
                        'question_length': len(question_text),
                        'ml_confidence': confidence,
                        'ml_explanation': explanation
                    }
                    columns = ', '.join(rejected_data.keys())
                    placeholders = ', '.join(['?' for _ in rejected_data])
                    query = f"INSERT INTO rejected_questions ({columns}) VALUES ({placeholders})"
                    cursor.execute(query, list(rejected_data.values()))
                
                question_id = cursor.lastrowid
                conn.commit()
                
                logger.debug(f"üìù –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –∞–Ω–∞–ª–∏—Ç–∏–∫—É (ID: {question_id})")
                return question_id
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞ –≤ –∞–Ω–∞–ª–∏—Ç–∏–∫—É: {e}")
            return -1
    
    def _extract_keywords(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
        import re
        
        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        stop_words = {
            '–∫–∞–∫', '—á—Ç–æ', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '–∫—Ç–æ', '–∫–∞–∫–æ–π', '–∫–∞–∫–∞—è', '–∫–∞–∫–∏–µ',
            '–≤', '–Ω–∞', '—Å', '–ø–æ', '–¥–ª—è', '–æ—Ç', '–¥–æ', '–ø—Ä–∏', '–∑–∞', '–ø–æ–¥', '–Ω–∞–¥', '–º–µ–∂–¥—É',
            '–∏', '–∏–ª–∏', '–Ω–æ', '–∞', '–¥–∞', '–Ω–µ—Ç', '–Ω–µ', '–Ω–∏', '–∂–µ', '–ª–∏', '–±—ã', '—Ç–æ',
            '—ç—Ç–æ', '—ç—Ç–æ—Ç', '—ç—Ç–∞', '—ç—Ç–∏', '—Ç–æ—Ç', '—Ç–∞', '—Ç–µ'
        }
        
        words = re.findall(r'\b[–∞-—è—ëa-z]+\b', text.lower())
        keywords = [word for word in words if word not in stop_words and len(word) > 2]
        return keywords[:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    
    def _categorize_question(self, text: str, keywords: List[str]) -> str:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤–æ–ø—Ä–æ—Å–∞."""
        text_lower = text.lower()
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        categories = {
            '–Ω–∞–ª–æ–≥–∏': ['–Ω–∞–ª–æ–≥', '–ø–æ–¥–æ—Ö–æ–¥–Ω—ã–π', '–Ω–¥—Å', '–Ω–∞–ª–æ–≥–æ–æ–±–ª–æ–∂–µ–Ω–∏–µ', '–¥–µ–∫–ª–∞—Ä–∞—Ü–∏—è', '–ª—å–≥–æ—Ç–∞'],
            '—Ç—Ä—É–¥–æ–≤—ã–µ_–æ—Ç–Ω–æ—à–µ–Ω–∏—è': ['—Ç—Ä—É–¥–æ–≤–æ–π', '–¥–æ–≥–æ–≤–æ—Ä', '—É–≤–æ–ª—å–Ω–µ–Ω–∏–µ', '–∑–∞—Ä–ø–ª–∞—Ç–∞', '–æ—Ç–ø—É—Å–∫', '–±–æ–ª—å–Ω–∏—á–Ω—ã–π'],
            '—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è_–±–∏–∑–Ω–µ—Å–∞': ['–∏–ø', '—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è', '–ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å', '–æ–æ–æ', '–ª–∏—Ü–µ–Ω–∑–∏—è'],
            '—Å–µ–º–µ–π–Ω–æ–µ_–ø—Ä–∞–≤–æ': ['—Ä–∞–∑–≤–æ–¥', '–∞–ª–∏–º–µ–Ω—Ç—ã', '–±—Ä–∞–∫', '–Ω–∞—Å–ª–µ–¥—Å—Ç–≤–æ', '–æ–ø–µ–∫–∞'],
            '–Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å': ['–∫–≤–∞—Ä—Ç–∏—Ä–∞', '–¥–æ–º', '–∞—Ä–µ–Ω–¥–∞', '–ø–æ–∫—É–ø–∫–∞', '–ø—Ä–æ–¥–∞–∂–∞', '–Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å'],
            '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ_–ø—Ä–∞–≤–æ–Ω–∞—Ä—É—à–µ–Ω–∏—è': ['—à—Ç—Ä–∞—Ñ', '–Ω–∞—Ä—É—à–µ–Ω–∏–µ', '–≥–∏–±–¥–¥', '–∫–æ–∞–ø', '–ø—Ä–æ—Ç–æ–∫–æ–ª'],
            '–≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–µ_—Å–ø–æ—Ä—ã': ['–∏—Å–∫', '—Å—É–¥', '–≤–æ–∑–º–µ—â–µ–Ω–∏–µ', '—É—â–µ—Ä–±', '–¥–æ–≥–æ–≤–æ—Ä'],
            '—Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ_–≤–æ–ø—Ä–æ—Å—ã': ['–ø–µ–Ω—Å–∏—è', '–ø–æ—Å–æ–±–∏–µ', '–ª—å–≥–æ—Ç—ã', '–∏–Ω–≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å', '–º–∞—Ç–µ—Ä–∏–Ω—Å–∫–∏–π'],
            '–¥–æ–∫—É–º–µ–Ω—Ç–æ–æ–±–æ—Ä–æ—Ç': ['—Å–ø—Ä–∞–≤–∫–∞', '–¥–æ–∫—É–º–µ–Ω—Ç—ã', '–ø–∞—Å–ø–æ—Ä—Ç', '–≤–∏–∑–∞', '–∑–∞–≥—Ä–∞–Ω–ø–∞—Å–ø–æ—Ä—Ç']
        }
        
        for category, category_keywords in categories.items():
            if any(keyword in text_lower for keyword in category_keywords):
                return category
        
        return '–æ–±—â–∏–µ_–≤–æ–ø—Ä–æ—Å—ã'
    
    def get_analytics_summary(self, days: int = 30) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–≤–æ–¥–∫—É –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.
        
        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                cursor.execute("""
                    SELECT 
                        COUNT(*) as total_questions,
                        AVG(ml_confidence) as avg_confidence,
                        COUNT(CASE WHEN ml_confidence < 0.7 THEN 1 END) as low_confidence,
                        COUNT(CASE WHEN ml_confidence > 0.9 THEN 1 END) as high_confidence,
                        COUNT(CASE WHEN source_type = 'dynamic_search' THEN 1 END) as dynamic_searches
                    FROM user_questions 
                    WHERE timestamp >= datetime('now', '-{} days')
                """.format(days))
                
                accepted_stats = cursor.fetchone()
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
                cursor.execute("""
                    SELECT 
                        COUNT(*) as rejected_count,
                        AVG(ml_confidence) as avg_rejected_confidence
                    FROM rejected_questions 
                    WHERE timestamp >= datetime('now', '-{} days')
                """.format(days))
                
                rejected_stats = cursor.fetchone()
                
                # –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–π
                cursor.execute("""
                    SELECT question_category, COUNT(*) as count
                    FROM user_questions 
                    WHERE timestamp >= datetime('now', '-{} days')
                    GROUP BY question_category 
                    ORDER BY count DESC 
                    LIMIT 10
                """.format(days))
                
                top_categories = cursor.fetchall()
                
                return {
                    'period_days': days,
                    'total_questions': accepted_stats[0] or 0,
                    'rejected_questions': rejected_stats[0] or 0,
                    'avg_confidence': round(accepted_stats[1] or 0, 3),
                    'avg_rejected_confidence': round(rejected_stats[1] or 0, 3),
                    'low_confidence_count': accepted_stats[2] or 0,
                    'high_confidence_count': accepted_stats[3] or 0,
                    'dynamic_searches': accepted_stats[4] or 0,
                    'top_categories': [{'category': cat, 'count': count} for cat, count in top_categories],
                    'ml_accuracy_estimate': self._estimate_accuracy(days)
                }
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}")
            return {'error': str(e)}
    
    def _estimate_accuracy(self, days: int) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å ML-—Ñ–∏–ª—å—Ç—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Å–≤–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è (–æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–∏–Ω—è—Ç—ã—Ö)
                cursor.execute("""
                    SELECT COUNT(*) FROM user_questions 
                    WHERE ml_confidence < 0.6 AND timestamp >= datetime('now', '-{} days')
                """.format(days))
                likely_false_positives = cursor.fetchone()[0]
                
                # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–ø—É—Å–∫–∏ (–≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã—Ö)
                cursor.execute("""
                    SELECT COUNT(*) FROM rejected_questions 
                    WHERE ml_confidence > 0.8 AND timestamp >= datetime('now', '-{} days')
                """.format(days))
                likely_false_negatives = cursor.fetchone()[0]
                
                cursor.execute("""
                    SELECT COUNT(*) FROM user_questions 
                    WHERE timestamp >= datetime('now', '-{} days')
                """.format(days))
                total_accepted = cursor.fetchone()[0]
                
                cursor.execute("""
                    SELECT COUNT(*) FROM rejected_questions 
                    WHERE timestamp >= datetime('now', '-{} days')
                """.format(days))
                total_rejected = cursor.fetchone()[0]
                
                total_questions = total_accepted + total_rejected
                
                if total_questions > 0:
                    estimated_accuracy = 1 - (likely_false_positives + likely_false_negatives) / total_questions
                    return {
                        'estimated_accuracy': round(max(0, estimated_accuracy), 3),
                        'likely_false_positives': likely_false_positives,
                        'likely_false_negatives': likely_false_negatives,
                        'total_questions': total_questions
                    }
                
                return {'estimated_accuracy': 0, 'insufficient_data': True}
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏: {e}")
            return {'error': str(e)}
    
    def export_training_data(self, output_file: str = "ml_training_data.csv", 
                           min_confidence: float = 0.8) -> bool:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è ML-–º–æ–¥–µ–ª–∏.
        
        Args:
            output_file: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
            min_confidence: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –¥–∞—Ç–∞—Å–µ—Ç
            
        Returns:
            True –µ—Å–ª–∏ —ç–∫—Å–ø–æ—Ä—Ç —É—Å–ø–µ—à–µ–Ω
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–∏–Ω—è—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                accepted_df = pd.read_sql_query("""
                    SELECT 
                        question_text,
                        1 as is_legal,
                        ml_confidence,
                        question_category,
                        keywords
                    FROM user_questions 
                    WHERE ml_confidence >= ?
                    ORDER BY timestamp DESC
                """, conn, params=[min_confidence])
                
                # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                rejected_df = pd.read_sql_query("""
                    SELECT 
                        question_text,
                        0 as is_legal,
                        ml_confidence,
                        'non_legal' as question_category,
                        '[]' as keywords
                    FROM rejected_questions 
                    WHERE ml_confidence >= ?
                    ORDER BY timestamp DESC
                """, conn, params=[min_confidence])
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                combined_df = pd.concat([accepted_df, rejected_df], ignore_index=True)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
                combined_df.to_csv(output_file, index=False, encoding='utf-8')
                
                logger.info(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(combined_df)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –≤ {output_file}")
                return True
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {e}")
            return False
    
    def get_low_confidence_questions(self, threshold: float = 0.7, limit: int = 50) -> List[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–æ–ø—Ä–æ—Å—ã —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    SELECT 
                        id, question_text, ml_confidence, ml_prediction, ml_explanation, timestamp
                    FROM user_questions 
                    WHERE ml_confidence < ?
                    ORDER BY ml_confidence ASC, timestamp DESC
                    LIMIT ?
                """, [threshold, limit])
                
                columns = ['id', 'question_text', 'ml_confidence', 'ml_prediction', 'ml_explanation', 'timestamp']
                return [dict(zip(columns, row)) for row in cursor.fetchall()]
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é: {e}")
            return []

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
_analytics_instance = None

def get_analytics() -> UserAnalytics:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏—Ç–∏–∫–∏."""
    global _analytics_instance
    if _analytics_instance is None:
        _analytics_instance = UserAnalytics()
    return _analytics_instance

def log_user_question(user_id: int, question_text: str, ml_result: Tuple[bool, float, str], 
                     search_results: Dict[str, Any] = None, response_info: Dict[str, Any] = None,
                     session_id: str = None) -> int:
    """–£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    return get_analytics().log_question(user_id, question_text, ml_result, search_results, response_info, session_id) 